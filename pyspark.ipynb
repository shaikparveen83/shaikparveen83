{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession.builder.appName(\"Our First Spark Example\").getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "I9y9XTnTY663",
        "outputId": "b4540f5c-62a9-47b0-cc2c-90fd5ff1bd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,978 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,644 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,116 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,566 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,246 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,400 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.2 kB]\n",
            "Fetched 12.4 MB in 5s (2,382 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=d6e78b54a3e5265128ad66bb44d85884f9a33357633e3ffec09528441c32986a\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ce84a28bfa0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://625c91fd807e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(\"Alice\",25),(\"Bod\",30),(\"Charlie\",35)]\n",
        "df=spark.createDataFrame(data,[\"Name\",\"Age\"])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOBIoOsPZrzN",
        "outputId": "5125f6f1-c15a-4cb9-82f9-267df2d40b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   Name|Age|\n",
            "+-------+---+\n",
            "|  Alice| 25|\n",
            "|    Bod| 30|\n",
            "|Charlie| 35|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyN3Vpw1Zp0P",
        "outputId": "9f3ffed7-bc83-42fd-cb39-1688b311372b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth=GoogleAuth()\n",
        "gauth.credentials=GoogleCredentials.get_application_default()\n",
        "drive=GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "xgpMigAncZts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "downloaded=drive.CreateFile({'id':\"12D7fQjfQJIJn2OBgpLg5ZrNIYGvw6ksP\"})\n",
        "downloaded.GetContentFile('diabetes.csv')"
      ],
      "metadata": {
        "id": "2oXw-32wcjTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc=spark.sparkContext\n",
        "path=\"diabetes.csv\"\n",
        "df=spark.read.csv(path)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8Jl7trSdNHk",
        "outputId": "3b6a6ffa-8beb-4806-b9af-10078d55173b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+--------------------+---+-------+\n",
            "|        _c0|    _c1|          _c2|          _c3|    _c4| _c5|                 _c6|_c7|    _c8|\n",
            "+-----------+-------+-------------+-------------+-------+----+--------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeF...|Age|Outcome|\n",
            "|          6|    148|           72|           35|      0|33.6|               0.627| 50|      1|\n",
            "|          1|     85|           66|           29|      0|26.6|               0.351| 31|      0|\n",
            "|          8|    183|           64|            0|      0|23.3|               0.672| 32|      1|\n",
            "|          1|     89|           66|           23|     94|28.1|               0.167| 21|      0|\n",
            "|          0|    137|           40|           35|    168|43.1|               2.288| 33|      1|\n",
            "|          5|    116|           74|            0|      0|25.6|               0.201| 30|      0|\n",
            "|          3|     78|           50|           32|     88|  31|               0.248| 26|      1|\n",
            "|         10|    115|            0|            0|      0|35.3|               0.134| 29|      0|\n",
            "|          2|    197|           70|           45|    543|30.5|               0.158| 53|      1|\n",
            "|          8|    125|           96|            0|      0|   0|               0.232| 54|      1|\n",
            "|          4|    110|           92|            0|      0|37.6|               0.191| 30|      0|\n",
            "|         10|    168|           74|            0|      0|  38|               0.537| 34|      1|\n",
            "|         10|    139|           80|            0|      0|27.1|               1.441| 57|      0|\n",
            "|          1|    189|           60|           23|    846|30.1|               0.398| 59|      1|\n",
            "|          5|    166|           72|           19|    175|25.8|               0.587| 51|      1|\n",
            "|          7|    100|            0|            0|      0|  30|               0.484| 32|      1|\n",
            "|          0|    118|           84|           47|    230|45.8|               0.551| 31|      1|\n",
            "|          7|    107|           74|            0|      0|29.6|               0.254| 31|      1|\n",
            "|          1|    103|           30|           38|     83|43.3|               0.183| 33|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+--------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc=spark.sparkContext\n",
        "path=\"diabetes.csv\"\n",
        "df=spark.read.csv(path,header=True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TcQ08LFezqE",
        "outputId": "94ffe313-ac02-497e-b045-89b2d48d8989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
            "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
            "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
            "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0|\n",
            "|          3|     78|           50|           32|     88|  31|                   0.248| 26|      1|\n",
            "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
            "|          8|    125|           96|            0|      0|   0|                   0.232| 54|      1|\n",
            "|          4|    110|           92|            0|      0|37.6|                   0.191| 30|      0|\n",
            "|         10|    168|           74|            0|      0|  38|                   0.537| 34|      1|\n",
            "|         10|    139|           80|            0|      0|27.1|                   1.441| 57|      0|\n",
            "|          1|    189|           60|           23|    846|30.1|                   0.398| 59|      1|\n",
            "|          5|    166|           72|           19|    175|25.8|                   0.587| 51|      1|\n",
            "|          7|    100|            0|            0|      0|  30|                   0.484| 32|      1|\n",
            "|          0|    118|           84|           47|    230|45.8|                   0.551| 31|      1|\n",
            "|          7|    107|           74|            0|      0|29.6|                   0.254| 31|      1|\n",
            "|          1|    103|           30|           38|     83|43.3|                   0.183| 33|      0|\n",
            "|          1|    115|           70|           30|     96|34.6|                   0.529| 32|      1|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "F03Vc2B2fcAE",
        "outputId": "51b4d83a-af54-4df9-c574-a88a06417d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfrdd=df.rdd\n",
        "type(dfrdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "kUsKHMFef7yU",
        "outputId": "b2813bf3-36ab-49e6-8bab-ac38f3c5bfcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfrdd.map(lambda c:(c[0],c[1],c[2],c[3])).take(4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puG5naRDgMU9",
        "outputId": "413d5b05-5426-4791-84f9-3453e4ae4120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('6', '148', '72', '35'),\n",
              " ('1', '85', '66', '29'),\n",
              " ('8', '183', '64', '0'),\n",
              " ('1', '89', '66', '23')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfrdd.map(lambda c:(c[0],c[1],c[2],c[3])).filter(lambda c:c[3]=='35').take(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC1r0X4_jRwx",
        "outputId": "4f8a16f5-6308-4b0e-c2b2-543a9e88f290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('6', '148', '72', '35'),\n",
              " ('0', '137', '40', '35'),\n",
              " ('9', '119', '80', '35'),\n",
              " ('6', '148', '72', '35'),\n",
              " ('0', '137', '40', '35')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"diabeticview\")\n",
        "from pyspark.sql import SQLContext\n",
        "sqlc=SQLContext(sc)\n",
        "sqlc.sql(\"select * from diabeticview\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbeJpsDWjykN",
        "outputId": "b6eb2658-ae9a-4087-de9e-8b7da2157ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
            "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
            "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
            "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
            "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
            "|          5|    116|           74|            0|      0|25.6|                   0.201| 30|      0|\n",
            "|          3|     78|           50|           32|     88|  31|                   0.248| 26|      1|\n",
            "|         10|    115|            0|            0|      0|35.3|                   0.134| 29|      0|\n",
            "|          2|    197|           70|           45|    543|30.5|                   0.158| 53|      1|\n",
            "|          8|    125|           96|            0|      0|   0|                   0.232| 54|      1|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sqlc.sql(\"select Glucose,BloodPressure,SkinThickness from diabeticview\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpJeTiJFjyZ3",
        "outputId": "48060ef2-a6df-4ea4-a85c-51358cf45c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+-------------+\n",
            "|Glucose|BloodPressure|SkinThickness|\n",
            "+-------+-------------+-------------+\n",
            "|    148|           72|           35|\n",
            "|     85|           66|           29|\n",
            "|    183|           64|            0|\n",
            "|     89|           66|           23|\n",
            "|    137|           40|           35|\n",
            "|    116|           74|            0|\n",
            "|     78|           50|           32|\n",
            "|    115|            0|            0|\n",
            "|    197|           70|           45|\n",
            "|    125|           96|            0|\n",
            "+-------+-------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sqlc.sql(\"select * from diabeticview where Glucose>180 and BloodPressure>100\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IF67VMejyPu",
        "outputId": "2c94cb7c-ec7d-4a41-d87b-f2587b548eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "|          0|    189|          104|           25|      0|34.3|                   0.435| 41|      1|\n",
            "|          4|    189|          110|           31|      0|28.5|                    0.68| 37|      0|\n",
            "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sqlc.sql(\"select Outcome,count(*) from diabeticview group by Outcome\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMeIQ3lvn0Vw",
        "outputId": "12495a25-4f96-42e2-f8e6-c01790550569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+\n",
            "|Outcome|count(1)|\n",
            "+-------+--------+\n",
            "|      0|     509|\n",
            "|      1|     286|\n",
            "+-------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simpleData=[(\"james\",\"sales\",3000),\n",
        "            (\"michal\",\"sales\",4600),\n",
        "            (\"robert\",\"sales\",4100),\n",
        "            (\"maria\",\"finance\",3000),\n",
        "            (\"james\",\"sales\",3000),\n",
        "            (\"scout\",\"finance\",3300),\n",
        "            (\"jeff\",\"marketing\",3000),\n",
        "            (\"kumar\",\"marketing\",2000),\n",
        "            (\"safi\",\"sales\",4300)]\n",
        "schema=[\"employee_name\",\"department\",\"salary\"]\n",
        "df=spark.createDataFrame(data=simpleData,schema=schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRYNrtoaoeQV",
        "outputId": "5d549de8-2a5b-497f-fda4-f931cf594795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|james        |sales     |3000  |\n",
            "|michal       |sales     |4600  |\n",
            "|robert       |sales     |4100  |\n",
            "|maria        |finance   |3000  |\n",
            "|james        |sales     |3000  |\n",
            "|scout        |finance   |3300  |\n",
            "|jeff         |marketing |3000  |\n",
            "|kumar        |marketing |2000  |\n",
            "|safi         |sales     |4300  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"empview\")\n",
        "from pyspark.sql import SQLContext\n",
        "sqlc=SQLContext(sc)\n",
        "sqlc.sql(\"select * from empview\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5_QgixfqZhX",
        "outputId": "eb193c79-78d6-4e70-817d-4d85b86c2d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|        james|     sales|  3000|\n",
            "|       michal|     sales|  4600|\n",
            "|       robert|     sales|  4100|\n",
            "|        maria|   finance|  3000|\n",
            "|        james|     sales|  3000|\n",
            "|        scout|   finance|  3300|\n",
            "|         jeff| marketing|  3000|\n",
            "|        kumar| marketing|  2000|\n",
            "|         safi|     sales|  4300|\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sqlc.sql(\"select department,sum(salary) from empview group by department\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQUXIW7hsKiv",
        "outputId": "4ce12006-1845-4f9f-bd40-e1513d240eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|department|sum(salary)|\n",
            "+----------+-----------+\n",
            "|   finance|       6300|\n",
            "|     sales|      19000|\n",
            "| marketing|       5000|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}